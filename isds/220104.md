# 220104 나는 무엇을 했는가?
## 10:30 ~ 12:00

### tutorial repository README.md
- git 사용방법

- Ubuntu(Linux) 기초 > 이 부분은 실제로 서버에 연결을 해봐야 감이 올 것 같음

  - 기본 명령어

    - pwd: 작업중인 디렉토리 출력

    - cd: 디렉토리 이동 (.. 상위, . 현재)

    - ls: 디렉토리 목록 확인 -l()

    - cp: 복사 / 디렉토리 복사는 -r 옵션

    - mv: 파일 혹은 디렉토리 이동 > 이름을 변경하는 용도로 많이 쓰임

    - mkdir: 디렉토리 생성

    - rm: 삭제 -f 경고 없이 삭제 -rf 경고없이 강제삭제 -ri 파일 하나하나 확인하며 삭제

    - touch: 업데이트 일자를 현재로 변경(0바이트 파일 만들때 자주 사용)

    - cat: cat file - 파일 내용 출력 / cat file1 file2 - 파일 덧붙이기

    - head: -N file file 상위 N줄 출력

    - tail: -N file file 하위 N줄 출력 (로그파일 모니터링할 때 자주 쓰임)

    - find: 특정 파일이나 디렉토리 검색 find [검색경로] -name [파일명] 

      ```shell
      $ find ./ -name "*.jpg" #확장자가 jpg인거 모두 찾기
      $ find ./ -name "*.jpg" -exec rm {} \; #찾아서 삭제
      $ find ./ -type d #directory
      $ find ./ -type f #file
      $ find ./ -type f | wc -l #갯수 반환
      $ find ./ -name "*.txt" -exec sed -i 's/hi/hello/g' {} \; #txt file 안에 hi를 hello로 변환
      ```

## 13:00 ~

### PyCharm 사용법

#### Debug

- **Breakpoints**

  - special markeers that suspend program execution at specific point

  - Line breakpoints - suspend the program upon reaching the line of code where the breakpoint was set

  - Exception breakpoints - suspend the program when Exception or its subclasses are thrown.

    pro 버전을 써야 장고, 자바 스크립트, jupyter 에서 사용 가능

  - line breakpoints: ctrl + f8

  - exception breakpoints: ctrl + shift + f8  >>> alt + insert >>> select [*] exception breakpoints

  - start debugger session: shift + f9

- **Remote Debugging with PyCharm**

  - only professional

  1. Through a remote interpreter

     - *Requirement*: SSH access from the local machine to the remote server

       **PyCharm 원격서버 연결하기**

       - remote interpreter 설정

         프로젝트 생성후 menu - file - setting - project - project interpreter - 톱날버튼 클릭 - add remote - depoyment configruation ... - + - 서버명 입력 - 서버타입 설정  - 원격서버 접속 정보 입력 - root path는 사용자의 home dir - ok - create - 원격 서버의 interpreter로 경로 설정

     - 원격으로 디버깅 가능할 때 사용

       

  2. Using the python remote debug server configuration
     - *Requirements:* SSH access from the local machine to the remote server, access from the remote server to the local machine using any predefined port.
     - Use this approach to integrate the debugging process into the series of running processes on the remote server. This might be helpful when you cannot explicitly run your application for debugging, or when some preparations tasks are required.
     - 원격 서버에서 실행되는 중에 디버깅 절차를 통합할 때 사용 (따로 디버깅 할 수 없을 때)

---

### 내일 세미나 논문 읽어 놓기

#### Style Tag

- **Abstract**
  - Style Tag를 사용해서 lingustic embedding과 speaking style domain의 관계를 모델링 할 수 있음
  - train 과정에서  style tag가 감춰져도 동작하도록 해줌
  - Style Tag는 자연어라 직관적이고 해석 가능하며, style index와 speech reference 방식에 비해 확장(?) 가능함 

- **Introduction**

  - AR model(Tactron2, Transformer TTS)은 느리고, attention이 실패할 경우 불안정적이기도 함.

  - NAR model은 많이 빨라짐

  - categorical style labels: 확장성 없음

  - reference speech: 직관적이지 않고, 해석할 수 없음. 심지어 시간이 오래걸리고, 메모리 활용이 비효율적임

    > Style Tag : 말의 스타일을 표현하는 짧은 문장이나 단어를 활용한 학습 방법 제안
    >
    > - 직관적이고 해석 가능함
    > - pre-train된 언어모델을 사용하기 때문에 linguistic embedding과 style embedding 공간의 관계를 학습할 수 있음
    >
    > - single stage ([Monotonic Alignment Search](https://arxiv.org/abs/2005.11129))

- **Style Tagging Dataset**
  - {speech, transcript, style tag}
  - normal reading book style(25%) 빼고는 다 style tag 있음
- **Style Tag TTS**
  - Sentence Bert
    - Contrastive Learning
    - Pre-trained
  - Style Encoder
    - Style Embedding을 추출하는 모듈
    - Reference Encoder와 Style Tag Encoder로 구성
    - [GST](https://arxiv.org/abs/1803.09017)의 Reference Encoder와 유사한 구조
    - style token을 사용 한 하고, batch normalization은 weight normalization으로 대체함
    - *Style Tag Encoder*
      - pre-trained SBERT + adaptation layers (3 ReLU Layers)
      - adaptation layers: linguistic semantic space 와 style embedding space를 mapping
    - RF Style Emb: TTS / ST Style Emb: MSE
  - Text Encoder
    - input: grapheme sequence
    - output: text embedding sequence (used for the aligner)
    - resiual dilated convolution blocks (parallel wavegan)
    - 5 kernel size 256 hidden dimension
  - Aligner
    - text와 log mel-spectrogram의 차이를 조정
    - 각 grapheme의 duration 반환
    - Glow-TTS에서 소개된 방법 차용 (NF, MAS)
    - 수식 부분 이후에 대한 설명은 세미나때 열심히 듣기..!
  - Duration predictor
    - predict the number of frames for each grapheme in log scale
    - residual convolution block (used in txt encoder)
    - different style yields different speaking speed
    - 5 residual block (5 kernel size 256 hidden dimension)
  - Mel-Encoder
    - 지속시간이 확장된 text embedding을 log-melspectogram으로 변환 (conditioned on a style embedding > style embedding이 적용된???)
    - 30 residual block
    - dilation rate: 1 2 4 8 16  
    - 3 kernel size 256 hidden dimension

- Training and Inference
  - Training
    - 4가지 loss 합(Mel reconstruction loss, Duration loss, Alignment loss, Style Embedding loss)
  - Inference
    - log scale duration > exponential operation and rounded to nearest integer
    - 예측한 duration이 1보다 작으면 1
    - Reference Speech나 style tag는 안 써도 됨

- 결과는 Tacotron2-GST 보다 좋음

---

*Training Gopher*는 길어서 읽기만 합니다!
